{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "9SjJ7-Hp-waz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG1-hHXosMQ8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg1AvGst5TMp"
      },
      "source": [
        "**Loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiPbl-fjTlUO"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train=np.array( x_train,dtype = float )\n",
        "y_train=np.array( y_train,dtype = float )\n",
        "x_test=np.array( x_test,dtype = float )\n",
        "y_test=np.array( y_test,dtype = float)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],-1)\n",
        "x_test = x_test.reshape(x_test.shape[0],-1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select classes 0 & 1**"
      ],
      "metadata": {
        "id": "JznzJ5x6ANnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train[(y_train == 1) | (y_train == 0)]\n",
        "y_train = y_train[(y_train == 1) | (y_train == 0)]\n",
        "\n",
        "x_test = x_test[(y_test == 1) | (y_test == 0)]\n",
        "y_test = y_test[(y_test == 1) | (y_test == 0)]"
      ],
      "metadata": {
        "id": "J40SoNkwCJOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardization**"
      ],
      "metadata": {
        "id": "xdSF-IxM-0Vo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozEE1xpWgOoF"
      },
      "outputs": [],
      "source": [
        "x_train= (x_train - np.mean(x_train))/ np.std(x_train)\n",
        "x_test= (x_test - np.mean(x_test))/ np.std(x_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Array split implementation**"
      ],
      "metadata": {
        "id": "_bJKYclX_LvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsOBcR2pyj_x"
      },
      "outputs": [],
      "source": [
        "def split(x , k):\n",
        "    fold_size = np.floor(x.shape[0] / k)\n",
        "    folds = []\n",
        "    for i in range(k):\n",
        "        first = int(i * fold_size)\n",
        "        end = int((i+1) * fold_size)\n",
        "        fold = x[first:end]\n",
        "        folds.append(fold)\n",
        "    return folds "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation funcion**"
      ],
      "metadata": {
        "id": "m7-SHSrL-41t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return (1/(1+np.exp(-z)))"
      ],
      "metadata": {
        "id": "1eIF7WnB-9EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy calculator**"
      ],
      "metadata": {
        "id": "1bSxQo8Z-_o-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvKd7fKP2saF"
      },
      "outputs": [],
      "source": [
        "def accuracy(ypred,y_test):\n",
        "    y_test=y_test.reshape(len(ypred),1)\n",
        "    ac = np.mean(ypred == y_test)*100\n",
        "\n",
        "    return ac"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict function**"
      ],
      "metadata": {
        "id": "kepShFOppq9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x_test,w,b):\n",
        "  sz = len(x_test)\n",
        "  z =  np.dot( w.T , x_test.T )+b\n",
        "  ypred = sigmoid(z)\n",
        "  ypred = ypred.T\n",
        "  ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "  \n",
        "  \n",
        "  return ypred"
      ],
      "metadata": {
        "id": "V4TenkIOptY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3Q7vhn4npX"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDAoHAuAf2yP"
      },
      "outputs": [],
      "source": [
        "def Logistic_regression(x_train , y_train , eta , iterations=1000):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "    \n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        z = np.dot(w.T,x_train.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "        \n",
        "        error.append(np.mean(((-y_train*np.log(phiz+tol))-(((1-y_train)*(np.log((1-phiz)+tol)))))))\n",
        "    \n",
        "        w = w - (eta * (np.dot((phiz - y_train).T , x_train )) / sz).T\n",
        "        b = b - eta * np.mean(phiz - y_train)\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "# adding 10 Fold CV\n",
        "def kfold_logistic(iterations):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    escores=[]\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = Logistic_regression(X_train,Y_train,eta[r],iterations) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logisitic regression with L1 regularization**"
      ],
      "metadata": {
        "id": "oJc9Kxqkn5BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L1_Logistic_regression(x_train , y_train , eta ,Lambda_, iterations=1000):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "    \n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        z = np.dot(w.T,x_train.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "\n",
        "        cost = (-y_train*np.log(phiz+tol)-(((1-y_train)*(np.log((1-phiz)+tol))))) + Lambda_ * np.sum(np.abs(w))\n",
        "        error.append(np.mean(cost))\n",
        "\n",
        "        w = w - (eta * (np.dot((phiz - y_train).T , x_train ) / sz).T + Lambda_ * np.sign(w))\n",
        "        b = b - eta * np.mean(phiz - y_train)\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "# adding 10 Fold CV\n",
        "def L1_kfold_logistic(Lambda_reg, iterations):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    Lambda_ = Lambda_reg\n",
        "    escores=[]\n",
        "\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = L1_Logistic_regression(X_train,Y_train,eta[r],Lambda_,iterations) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "            \n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e    "
      ],
      "metadata": {
        "id": "TgVS1vyNn0wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini-Batch gradient descent**\n"
      ],
      "metadata": {
        "id": "GndXNb3n4Egv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmyq8ib66uma"
      },
      "outputs": [],
      "source": [
        "def Mini_batch_logistic(x_train , y_train , eta , epochs=100,batch_size=100):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz0 = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "    \n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        ranges = np.random.choice(sz0, batch_size, replace=False)\n",
        "        x_mini = x_train[ranges]\n",
        "        y_mini = y_train[ranges]\n",
        "        sz = len(x_mini)\n",
        "\n",
        "        z = np.dot(w.T,x_mini.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "        \n",
        "        error.append(np.mean(((-y_mini*np.log(phiz+tol))-(((1-y_mini)*(np.log((1-phiz)+tol)))))))\n",
        "    \n",
        "        w = w - (eta * (np.dot((phiz - y_mini).T , x_mini )) / sz).T\n",
        "        b = b - eta * np.mean(phiz - y_mini)\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "# adding 10 Fold CV\n",
        "def Mini_Batch_kfold_logistic(epochs,batch_size):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    escores=[]\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = Mini_batch_logistic(X_train,Y_train,eta[r],epochs,batch_size) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMS Prop optimizer**\n"
      ],
      "metadata": {
        "id": "xgPFLQ7PLXwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-AsHIhgL3rL"
      },
      "outputs": [],
      "source": [
        "def RMS_Prop_Logistic_regression(x_train , y_train , eta , iterations=1000):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "\n",
        "    B2 = 0.999\n",
        "    eps = 0.0000001\n",
        "\n",
        "    v_w = np.zeros_like(w)\n",
        "    v_b = np.zeros_like(b)\n",
        "   \n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        z = np.dot(w.T,x_train.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "        \n",
        "        error.append(np.mean(((-y_train*np.log(phiz+tol))-(((1-y_train)*(np.log((1-phiz)+tol)))))))\n",
        "         \n",
        "        dw = (np.dot((phiz - y_train).T, x_train) / sz).T\n",
        "        db = np.mean(phiz - y_train)\n",
        "\n",
        "        v_w =B2 *v_w + (1 - B2)* (dw **2)\n",
        "        v_b= B2 * v_b +(1 - B2) * (db** 2)\n",
        "\n",
        "        w = w - (eta * dw) / (np.sqrt(v_w) + eps)\n",
        "        b = b - (eta * db) / (np.sqrt(v_b) + eps)\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "# adding 10 Fold CV\n",
        "def RMS_Prop_kfold_logistic(iterations):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    escores=[]\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = RMS_Prop_Logistic_regression(X_train,Y_train,eta[r],iterations) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e\n",
        "# RMS with Mini-Batch    \n",
        "def RMS_Prop_Mini_batch_logistic(x_train , y_train , eta , epochs=100,batch_size=500):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz0 = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "\n",
        "    B2 = 0.999\n",
        "    eps = 0.0000001\n",
        "\n",
        "    v_w = np.zeros_like(w)\n",
        "    v_b = np.zeros_like(b)\n",
        "\n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        ranges = np.random.choice(sz0, batch_size, replace=False)\n",
        "        x_mini = x_train[ranges]\n",
        "        y_mini = y_train[ranges]\n",
        "        sz = len(x_mini)\n",
        "        \n",
        "        z = np.dot(w.T,x_mini.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "        \n",
        "        error.append(np.mean(((-y_mini*np.log(phiz+tol))-(((1-y_mini)*(np.log((1-phiz)+tol)))))))\n",
        "\n",
        "        dw = (np.dot((phiz - y_mini).T, x_mini) / sz).T\n",
        "        db = np.mean(phiz - y_mini)\n",
        "\n",
        "        v_w =B2 *v_w + (1 - B2)* (dw **2)\n",
        "        v_b= B2 * v_b +(1 - B2) * (db** 2)\n",
        "\n",
        "        w = w - (eta * dw) / (np.sqrt(v_w) + eps)\n",
        "        b = b - (eta * db) / (np.sqrt(v_b) + eps)\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "# RMS, Mini-Bacth with kfold    \n",
        "def RMS_Prop_Mini_Batch_kfold_logistic(epochs,batch_size):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    escores=[]\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = RMS_Prop_Mini_batch_logistic(X_train,Y_train,eta[r],epochs,batch_size) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADAM optimizer**\n"
      ],
      "metadata": {
        "id": "UEBItyLaUwow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ADAM_Logistic_regression(x_train , y_train , eta , iterations=1000):\n",
        "    \n",
        "    np.random.seed(35)\n",
        "    w = np.random.rand(x_train.shape[1],1)\n",
        "    b = np.random.rand(1)\n",
        "    sz = len(x_train)\n",
        "    error = []\n",
        "    tol = 0.0000001\n",
        "\n",
        "    B1 = 0.9\n",
        "    B2 = 0.999\n",
        "    eps = 0.0000001\n",
        "    \n",
        "    # Momentum\n",
        "    M_v_w = np.zeros_like(w)\n",
        "    M_v_b = np.zeros_like(b)\n",
        "    \n",
        "    # RMS Prob\n",
        "    R_v_w = np.zeros_like(w)\n",
        "    R_v_b =np.zeros_like(b)\n",
        "\n",
        "    y_train = y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        z = np.dot(w.T,x_train.T)+b\n",
        "        phiz = sigmoid(z)\n",
        "        phiz = phiz.T\n",
        "        phiz = np.where(phiz>0.5 , 1 ,0)\n",
        "        \n",
        "        error.append(np.mean(((-y_train*np.log(phiz+tol))-(((1-y_train)*(np.log((1-phiz)+tol)))))))\n",
        "         \n",
        "        dw = (np.dot((phiz - y_train).T, x_train) / sz).T\n",
        "        db = np.mean(phiz - y_train)\n",
        "\n",
        "        # Momentum\n",
        "        M_v_w = B1* M_v_w +(1-B1)*dw\n",
        "        M_v_b = B1* M_v_b +(1-B1)*db\n",
        "\n",
        "        # RMS Prob\n",
        "        R_v_w =B1 *R_v_w + (1 - B1)* (dw **2)\n",
        "        R_v_b= B2 * R_v_b +(1 - B2) * (db** 2)\n",
        "        \n",
        "        # ADAM mixes Momentum with RMS Prop in the weights update equation\n",
        "        w = w - eta*(M_v_w/(np.sqrt(R_v_w+eps)))\n",
        "        b = b - eta*(M_v_b/(np.sqrt(R_v_b+eps)))\n",
        "\n",
        "        if error[i] <= tol:\n",
        "              break \n",
        "    return w,b\n",
        "\n",
        "# adding 10 Fold CV\n",
        "def ADAM_kfold_logistic(iterations):\n",
        "    eta=[0.0001 , 0.001 , 0.01 , 0.1,0.5]\n",
        "    escores=[]\n",
        "    sb=0 \n",
        "    wf=0\n",
        "    bf=0\n",
        "    for r in range(len(eta)):\n",
        "        k=10\n",
        "        x_folds = split(x_train,k)\n",
        "        y_folds = split(y_train,k)\n",
        "        scores = []\n",
        "\n",
        "        for i in range(k):\n",
        "            X_train = np.concatenate([x_folds[j] for j in range(k) if j != i])\n",
        "            Y_train = np.concatenate([y_folds[j] for j in range(k) if j != i])\n",
        "          \n",
        "            x_val = (x_folds[i])\n",
        "            y_val = (y_folds[i])\n",
        "          \n",
        "            w,b = ADAM_Logistic_regression(X_train,Y_train,eta[r],iterations) \n",
        "            \n",
        "            sz = len(y_val)\n",
        "            z =  np.dot( w.T , x_val.T )+b\n",
        "            ypred = sigmoid(z)\n",
        "            ypred = ypred.T\n",
        "            ypred = np.where(ypred>0.5 , 1 ,0)\n",
        "            y_val=y_val.reshape(sz,1)\n",
        "                \n",
        "            scores.append(round(accuracy(ypred,y_val),2))\n",
        "        if np.mean(scores)>sb:\n",
        "          sb=np.mean(scores)\n",
        "          wf=w\n",
        "          bf=b\n",
        "          e=eta[r]\n",
        "        escores.append(np.mean(scores))\n",
        "    return wf,bf,e\n",
        "            "
      ],
      "metadata": {
        "id": "sza_DJSEUzpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running L1 regularisation with 2 lambdas**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HhnbCacE31zg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1c0mPkezuvi",
        "outputId": "1d1f6375-7233-4b43-d5a0-213ab61ee1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with lambda_1 : 99.86%\n",
            "Accuracy with lambda_2 : 53.66%\n"
          ]
        }
      ],
      "source": [
        "lambda_1=0.001 \n",
        "lambda_2=1\n",
        "\n",
        "w1,b1, e1 = L1_kfold_logistic(Lambda_reg= lambda_1 ,iterations = 100)\n",
        "w2,b2, e2 = L1_kfold_logistic(Lambda_reg= lambda_2 ,iterations = 100)\n",
        "\n",
        "ypred = predict(x_test,w1,b1)\n",
        "print(\"Accuracy with lambda_1 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")\n",
        "\n",
        "ypred = predict(x_test,w2,b2)\n",
        "print(\"Accuracy with lambda_2 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Mini-Batch logistic**"
      ],
      "metadata": {
        "id": "xAJ9O7pK9-2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size1= 100\n",
        "size2= 500\n",
        "size3= 1000\n",
        "size4= 2000\n",
        "size5= 4000\n",
        "\n",
        "\n",
        "w1,b1,e1 = Mini_Batch_kfold_logistic(epochs = 100, batch_size = size1)# 5 sec\n",
        "w2,b2,e2 = Mini_Batch_kfold_logistic(epochs = 100, batch_size = size2)# 10 sec\n",
        "w3,b3,e3 = Mini_Batch_kfold_logistic(epochs = 100, batch_size = size3)# 15 sec\n",
        "w4,b4,e4 = Mini_Batch_kfold_logistic(epochs = 100, batch_size = size4)# 25 sec\n",
        "w5,b5,e5 = Mini_Batch_kfold_logistic(epochs = 100, batch_size = size5)# 50 sec\n",
        "\n",
        "\n",
        "ypred = predict(x_test,w1,b1)\n",
        "print(\"Accuracy with size=100 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"in time 5 sec\")\n",
        "\n",
        "ypred = predict(x_test,w2,b2)\n",
        "print(\"Accuracy with size=500 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"in time 10 sec\")\n",
        "\n",
        "ypred = predict(x_test,w3,b3)\n",
        "print(\"Accuracy with size=1000 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"in time 15 sec\")\n",
        "\n",
        "ypred = predict(x_test,w4,b4)\n",
        "print(\"Accuracy with size=2000 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"in time 25 sec\")\n",
        "\n",
        "ypred = predict(x_test,w5,b5)\n",
        "print(\"Accuracy with size=4000 :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"in time 50 sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv-NMMIyydoF",
        "outputId": "e3639bb5-afcd-4661-e286-2a677dc328ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with size=100 : 98.77% in time 5 sec\n",
            "Accuracy with size=500 : 99.24% in time 10 sec\n",
            "Accuracy with size=1000 : 99.81% in time 15 sec\n",
            "Accuracy with size=2000 : 99.81% in time 25 sec\n",
            "Accuracy with size=4000 : 99.76% in time 50 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running RMS Prop**"
      ],
      "metadata": {
        "id": "B2S9ha3gQGoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#whole gradient descent without optimizers\n",
        "w1,b1,e1 = kfold_logistic(iterations = 100)\n",
        "\n",
        "#whole gradient with RMS Prop\n",
        "w2,b2,e2 = RMS_Prop_kfold_logistic(iterations = 100)\n",
        "\n",
        "#Mini-Batch gradient descent with RMS Prop GET HIGHER ACCURACY in LESS TIME \n",
        "w3,b3,e3 = RMS_Prop_Mini_Batch_kfold_logistic(epochs = 100,batch_size = 1000)\n",
        "\n",
        "ypred = predict(x_test,w1,b1)\n",
        "print(\"Accuracy WITHOUT RMS Prop :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")\n",
        "\n",
        "ypred = predict(x_test,w2,b2)\n",
        "print(\"Accuracy whole batch WITH RMS Prop :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")\n",
        "\n",
        "ypred = predict(x_test,w3,b3)\n",
        "print(\"Accuracy Mini-Batch WITH RMS Prop :\",str(np.round(accuracy(ypred,y_test),2))+\"%\",\"HIGHER ACCURACY IN LESS TIME\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw9BZAxvLIFW",
        "outputId": "c0fc5f70-a580-4462-d354-46c263c56f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT RMS Prop : 99.81%\n",
            "Accuracy whole batch WITH RMS Prop : 99.95%\n",
            "Accuracy Mini-Batch WITH RMS Prop : 99.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running ADAM**"
      ],
      "metadata": {
        "id": "hH5kFHjEYGyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#whole gradient descent without optimizers\n",
        "w1,b1,e1 = kfold_logistic(iterations = 100)\n",
        "\n",
        "#whole gradient with ADAM\n",
        "w2,b2,e2 = ADAM_kfold_logistic(iterations = 100)\n",
        "\n",
        "\n",
        "ypred = predict(x_test,w1,b1)\n",
        "print(\"Accuracy WITHOUT ADAM :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")\n",
        "\n",
        "ypred = predict(x_test,w2,b2)\n",
        "print(\"Accuracy WITH ADAM :\",str(np.round(accuracy(ypred,y_test),2))+\"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7Mbwq2AYKZ1",
        "outputId": "8dad4e4d-c80c-49dc-82ae-ef6f0b01a63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT ADAM : 99.81%\n",
            "Accuracy WITH ADAM : 99.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Report:**\n",
        "  **L1:**\n",
        "     We can notice the effect of the L1 reg which aims to minimize the accuracy as to get rid of the overfitting problem \n",
        "     first lambda was too small, so it worked inversely and increased the dependency of the features and increased the accuracy.\n",
        "     meanwhile second lambda did the L1 job and decreased the dependency on some features so the accuracy decreased.\n",
        "\n",
        "  **Mini-Batch:**\n",
        "     We can see the difference in executing time between diferrent batch sizes and the difference of the final accuracy we get\n",
        "     for conclusion-> the higher batch size the higher accuracy we get and higher executing time needed so we can manage between them.\n",
        "\n",
        "\n",
        "  **RMS:**\n",
        "     We notice the big difference in accuracy specially with Mini-Batch gradient descent.\n",
        "\n",
        "  **ADAM:**\n",
        "     As expected ADAM is getting a higher accuracy all past methods got.  \n",
        "     \n"
      ],
      "metadata": {
        "id": "oj7dR04WBiEi"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}